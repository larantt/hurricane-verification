{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the TC custom dataframes\n",
    "* Lara Tobias-Tarsh (laratt@umich.edu)\n",
    "* Created: 16/03/2023\n",
    "\n",
    "This tutorial should cover how to use the custom data classes that I created for storing tropical cyclone (TC) track data from the Thorpex Grand Global Ensemble (TIGGE) and the HURDAT2 best track archive. This should dramatically simplify how information is stored in verification and also allows for some basic verification and comparison calculations to be done relatively simply.\n",
    "\n",
    "In my (lazy) opinion, this is way easier than having all the data floating around in a bunch of random functions and csv files :)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising a cyclone object\n",
    "\n",
    "The first step to using the TC custom dataframes is to import the track_error module. Think of this like a C++ .h file from 101, or like a python library. Once you import the module, you can use it like you would use a python library (e.g. numpy). \n",
    "\n",
    "\n",
    "You need to have the module in the same directory as the notebook you are working in to use it, so work in the errorCalcModules directory when you are doing analysis, or define a filepath to the module before you import it.\n",
    "\n",
    "\n",
    "You need all of the imports below to do this, as they are dependecies for the cyclone module itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform imports\n",
    "import numpy as np\n",
    "import track_error as te # the name you use to import this is arbitrary, I just used te bc it is an easy shorthand"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your imports, you can start to initialise your Cyclone objects. \n",
    "\n",
    "The only important thing here is the way your csv files are stored in their directories. You need to have each TC's csv files stored in a seperate directory so that the string parsing can work correctly. I will probably fix this at some point so that it can be done by just storing everything in one directory, but right now I can't be bothered to write the function... (sorry ANL...)\n",
    "\n",
    "\n",
    "I have organised the files on the github repo the same way that I have organised the files on my laptop when I tested all the code (TBA...), so if you clone the repo exactly you should have 0 problems with this. If you want to do this from scratch, you want to change the directory structure, or you have other models you want to include, this is how I have my directories structured:\n",
    "\n",
    "\n",
    "```\n",
    ".../tcTracks/cycName/stormName-year-month-day-hour.csv\n",
    "```\n",
    "\n",
    "All TIGGE tracks should be stored this way because the function uses the directory name to extract the name and year of the storm. I think this is a useful and organised way to store all of the data anyway, so I doubt I will change the syntax as it stops me getting lazy with file organisation while letting me be a lazy coder :)\n",
    "\n",
    "\n",
    "All you need to do to initialise a cyclone object is call the cyclone constructor, called generate_cyclone(). This takes only a filepath to a directory as an argument and does all of the work for you from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: Arthur-2020-05-17-12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laratobias-tarsh/opt/anaconda3/envs/tcVerification/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/laratobias-tarsh/opt/anaconda3/envs/tcVerification/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# here we initialise one cyclone\n",
    "filepath = \"/Users/laratobias-tarsh/Documents/clim323-final/tcTracks/Arthur\"\n",
    "cyclone = te.generate_cyclone(filepath)\n",
    "cyclone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acessing data in the object\n",
    "\n",
    "The TC object is a bunch of classes thrown together to create a 'Cyclone object' which contains all of the information for each storm. It is kind of like a custom matrix or dictionary with a bunch of lists inside it. This is why just printing it looks gross.\n",
    "\n",
    "The nice thing about this format is you can just use dot indexing to find things and means that you don't have loads of lists that you have to index logically or numerically floating around. It is therefore WAY easier to keep track of all of the data for each system.\n",
    "\n",
    "The object has a ton of attributes and methods that can be called to perform various operations, including embedded functions. We will start with the cyclone itself. This is the main frame that contains all the other lists of data. It also lets us see some summary statistics of the storm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'print_summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# See storm summary:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cyclone\u001b[39m.\u001b[39;49mprint_summary()\n\u001b[1;32m      4\u001b[0m \u001b[39m# See storm best track:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cyclone\u001b[39m.\u001b[39mtrack_map()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'print_summary'"
     ]
    }
   ],
   "source": [
    "# See storm summary:\n",
    "cyclone.print_summary()\n",
    "\n",
    "# See storm best track:\n",
    "cyclone.track_map()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing you want to look at is the individual model runs. They should be ordered chronologically, so the first run in the list is the first time the model was initialised and so on. They each contain some simple error statistics for the speciific run, and the individual coordinates of the storm at each forecast hour. \n",
    "\n",
    "You can access these in the runs attribute of the cyclone object, and then index into them like you would any other list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the first ECMWF run for this system:\n",
    "cyclone.ecmwf.runs[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a track object, which is just a list of datapoints about the cyclone, and the run's specific mean track error and mean intensity error. We can unpack this further to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets examine the summary statistics\n",
    "meanTrackError = cyclone.ecmwf.runs[0].mean_terror\n",
    "meanIntensityError = cyclone.ecmwf.runs[0].mean_ierror\n",
    "\n",
    "print(f'Mean Track Error {meanTrackError}')\n",
    "print(f'Mean Intensity Error: {meanIntensityError}')\n",
    "\n",
    "# Now we look at the positions themselves. We break these down like so:\n",
    "cyclone.ecmwf.runs[0].forecasts[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a position from the TIGGE archive for the system at a specific time. We can use . indexing to access all of these statistics individually as well if we want to. If you change this . index to either time, lat, lon, mslp, vmax, track_error or intensity_error you will be able to directly access this datum. \n",
    "\n",
    "Try changing it in the cell below to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone.ecmwf.runs[0].forecasts[0].track_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcVerification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87204725ff53e96471d7c683d49c35a1683b4af84a7578b6adf60afde351c601"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
